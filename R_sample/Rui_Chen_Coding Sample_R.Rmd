---
title: "Metrics Exercise"
author: "Rui Chen"
output:
  pdf_document: default
  html_document: default
date: "2024-01-05"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r cars}
rm(list=ls()) 
```

```{r}
setwd("D:/OneDrive - The University of Chicago/Academics/Big data/Metric analysis")
```

```{r}
# Introduction: This is the coding from a Metric Exercise of the Big Data and Development Course
# In this code, I delve into the analysis of a Harvest and Displacement working paper dataset of Afghanistan mobile data and some behavior pattern, and data regarding community trends and agricultural production. We start by exploring the 2021 mobile device data, generating summary statistics and creating at least one informative visual representation. Potential trends to explore include user ping frequency, user drop-off patterns, time-of-day analysis, and behavioral changes around notable dates such as May 1 and August 15. 

# Additionally, I draw the maps presented in the paper. The community trends and agricultural dataset includes violence data, provincial and district-level crop calendars, 2021 NDVI, 2020 and 2021 price data, takeover dates, and information on rainfed and irrigated cropland. We produce meaningful visualizations at the 2.5 x 2.5 km grid cell or district level to see 1) Agricultural Production and geographic distribution; 2) Whether Taliban takeover is happening in the harvest season; 3) Wheat production and average wheat price in year 2021
```

## Problem 2a

```{r}
mdd <- read.csv("D:/OneDrive - The University of Chicago/Academics/Big data/Metric analysis/BDD Exercise/DATA/2021_mobile_device_data.csv")
```


```{r}
library(lubridate)
library(dplyr)

mdd <- mdd %>% filter(num_pings >= 10)

mdd$utc_timestamp <- as.POSIXct(mdd$utc_timestamp, tz = "UTC")
mdd$hour <- hour(mdd$utc_timestamp)
mdd$date <- date(mdd$utc_timestamp)
summary(mdd)

```

```{r}
# group by device id to identity the first time and last time ping
mdd_1 <- mdd %>%
  group_by(caid) %>%
  summarise(utc_time_first = first(utc_timestamp),
            utc_date_first = first(utc_date),
            utc_time_last = last(utc_timestamp),
            utc_date_last = last(utc_date),
            altitude_first = first(altitude),
            longitude_first = first(longitude),
            latitude_first = first(latitude),
            altitude_last = last(altitude),
            longitude_last = last(longitude),
            latitude_last = last(latitude),
            num_pings = mean(num_pings),
            displacement = ifelse(n_distinct(ID) > 1, 1, 0),
            displace_time = ifelse(displacement == 1, first(utc_timestamp[ID != first(ID)]), NA_real_))  # consider a person "displaced" if same device is having ping activities at different dwell locations, which correspond with different IDs.Consider the displacement

mdd_1$date_first <- date(mdd_1$utc_date_first)  #date where first appearing in the data
mdd_1$displace_time <- as.POSIXct(mdd_1$displace_time, tz = "UTC")   #the displacement time
mdd_1$displace_date <- date(mdd_1$displace_time)
head(mdd_1)

```

```{r}

# Q: in what hour of the day does most pings happen?
library(ggplot2)
ggplot(mdd, aes(x = hour)) + 
  geom_histogram(binwidth = 1, fill = "grey", color = "black") + 
  labs(x = "Hour of the day", 
       y = "Frequency", 
       title = "Pings Activity by Hour of Day") + 
  scale_x_continuous(breaks = 0:23) + 
  theme_minimal()
```




```{r}
# Q: in what date does most devices operate?
library(ggplot2)
mdd_summary <- mdd %>%
  group_by(date) %>%
  summarise(date_counts = n())

ggplot(mdd_summary, aes(x = date, y = date_counts)) + 
  geom_line(group=1, color="blue") +
  labs(title = "Mobile Activities by Date", x = "Date", y = "Number of Activities") +
  theme_minimal()

```

```{r}
# Q: in what date does more devices entering into the data?
library(ggplot2)
mdd_1$date_first <- date(mdd_1$utc_date_first)

ggplot(mdd_1, aes(x= date_first)) +
  geom_bar(fill="gray", color="black") +  
  labs(title="Pings Activities by starting Date", x="Date", y="Frequency") +
  theme_minimal() 

```



```{r}
# Ping numbers distributions (top 50 devices) 
library(ggplot2)
ggplot (mdd_1 %>%
  arrange (desc(num_pings)) %>% head (50), aes(y= num_pings,
  x=reorder(caid, -num_pings))) +  
  geom_bar(position ="dodge", stat ="identity") 
```


```{r}
# Q: frequency of displacement
displacement_summary <- mdd_1 %>%
  group_by(displace_date) %>%
  summarise(displace_counts = n())

library(ggplot2)

ggplot(displacement_summary, aes(x = displace_date, y = displace_counts)) +
  geom_bar(position = "dodge", stat = "identity") +
  labs(title = "Displacement by Date", x = "Date", y = "Number of Displacements") +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 1500)) 
```


## Problem 2b

```{r}
#read the data of crop type
crop_cal_by_district <- read.csv("D:/OneDrive - The University of Chicago/Academics/Big data/Metric analysis/BDD Exercise/DATA/RAW/crop_cal_by_district.csv")
head(crop_cal_by_district)
```

```{r}
#read the data of take-over dates
takeover_dates <- read.csv("D:/OneDrive - The University of Chicago/Academics/Big data/Metric analysis/BDD Exercise/DATA/RAW/takeover_dates.csv")
head(takeover_dates)
```


```{r}
# Merge the corp data and takeover datasets by distid. 
merged_district <- left_join(crop_cal_by_district, takeover_dates, by = "distid")

merged_district <- merged_district %>%
  rename(DISTID = distid)

head(merged_district)
```


If you are making a district level map, use the next two code blocks:

```{r}
library(sf)
dist_sf <- st_read("D:/OneDrive - The University of Chicago/Academics/Big data/Metric analysis/BDD Exercise/DATA/398", layer = "district398")
dist_sf_new <- left_join(dist_sf, merged_district, by = "DISTID", relationship = "many-to-many")
```

```{r}
# Agricultural Production and geographic distribution

library(ggplot2)

dist_sf_new <- dist_sf_new %>%
  mutate(crop_category = case_when(
    crop == "Wheat" ~ "Rainfed Wheat",
    crop %in% c("Irrigated wheat winter", "Irrigated wheat summer") ~ "Irrigated Wheat"))

corp_type <-ggplot(data = dist_sf_new) +
  geom_sf(aes(fill = crop_category), color = "white") +
  scale_fill_manual(values = c("Rainfed Wheat" = "lightgreen", "Irrigated Wheat" = "darkgreen")) +
  guides(fill = guide_legend(title = "Wheat type", order=1)) +
  ggtitle("Wheat Type")

corp_type

```

```{r}
# Whether Taliban takeover is happening in the harvest season?
dist_sf_new <- dist_sf_new %>%
    mutate(take_over_during_harvest = ifelse (
      tal_switch_ymd >= begin_harv_blend & tal_switch_ymd <= end_harv_blend, "yes","no"))

take_over <-ggplot(data = dist_sf_new) +
  geom_sf(aes(fill = take_over_during_harvest)) +
  scale_fill_manual(values = c("yes" = "darkgreen", "no" = "lightgreen")) +
  guides(fill = guide_legend(title = "take_over_during_harvest_season", order=1)) +
  ggtitle("Taliban Takeover During Harvest Season?")

take_over

```


# Using grid cell level map to explore corp production, prices and violence level
If you are making a grid cell level map, use the next two code blocks:

```{r}
ndvi_2021 <- read.csv("D:/OneDrive - The University of Chicago/Academics/Big data/Metric analysis/BDD Exercise/DATA/RAW/ndvi_2021.csv")
```

```{r}
price_2021_interpolate <- read.csv("D:/OneDrive - The University of Chicago/Academics/Big data/Metric analysis/BDD Exercise/DATA/RAW/price_2021_interpolate.csv")
```

```{r}
wheat_prices_2021 <- read.csv("D:/OneDrive - The University of Chicago/Academics/Big data/Metric analysis/BDD Exercise/DATA/RAW/2021_wheat_prices.csv")
```


```{r}
#pick out the longitude, latitude, and desired vector from the merged dataframe
library(raster)
ndvi_data <- data.frame(lon = ndvi_2021[, 2], lat = ndvi_2021[, 3], ndvi = ndvi_2021[, 4])
#convert them to a raster here
ndvi <- rasterFromXYZ(ndvi_data)
```


```{r}
plot(ndvi,main = "Wheat Production in 2021, Measured by the 95th Percentile NDVI Value")  # ndvi
```

```{r}
#pick out the longitude, latitude, and desired vector from the merged dataframe
avg_price_data <- data.frame(lon = price_2021_interpolate[, 2], lat = price_2021_interpolate[, 3], avg_price = price_2021_interpolate[, 4])
#convert them to a raster here
avg_price <- rasterFromXYZ(avg_price_data)
```


```{r}
plot(avg_price, main = "Average Wheat Price in 2021")  # average wheat price in 2021
```





## Problem 4a

```{r}
pri_dat <- read.csv("D:/OneDrive - The University of Chicago/Academics/Big data/Metric analysis/BDD Exercise/DATA/primary_data.csv")
```

```{r}
head(pri_dat)
```

```{r}

library(dplyr)

pri_dat_agri <- pri_dat %>%
  filter(!(irrigated == 0 & rainfed == 0) | (!is.na(irrigated) & !is.na(rainfed))) %>%  # only filter the agricultural regions
  mutate(log_price = (price21 - price20)/price20) %>%
  group_by(caid) %>%
  summarize(
    treat = mean(treat, na.rm = TRUE),
    ndvi = mean(ndvi, na.rm = TRUE),
    log_price = mean(log_price, na.rm = TRUE),
    price20 = mean(price20, na.rm = TRUE),
    district = last(district),
    utc_date = last(utc_date),
    longitude = last(longitude),
    latitude = last(latitude)
  ) %>%
  ungroup() %>%
  mutate(take_over = ifelse(treat==0, 0, 1))

library(plm)

pri_dat_agri$district <- as.factor(pri_dat_agri$district)
pri_dat_agri$utc_date <- as.factor(pri_dat_agri$utc_date)

reg1 <- plm(log_price ~ ndvi + take_over, 
            data = pri_dat_agri, index = c("district", "utc_date"), model = "within")
summary(reg1)

```


```{r}

library(dplyr)

pri_dat_non_agri <- pri_dat %>%
  filter(irrigated == 0 & rainfed == 0) %>%  # only filter the non-agricultural regions
  mutate(log_price = (price21 - price20)/price20) %>%
  group_by(caid) %>%
  summarize(
    treat = mean(treat, na.rm = TRUE),
    ndvi = mean(ndvi, na.rm = TRUE),
    log_price = mean(log_price, na.rm = TRUE),
    price20 = mean(price20, na.rm = TRUE),
    district = last(district),
    utc_date = last(utc_date),
    longitude = last(longitude),
    latitude = last(latitude)
  ) %>%
  ungroup() %>%
  mutate(take_over = ifelse(treat==0, 0, 1))

library(plm)

# The regression on whether take-over is affecting the log price (only limited to non-agricultural districts)
reg2 <- plm(log_price ~ ndvi + take_over, 
            data = pri_dat_non_agri, index = c("district", "utc_date"), model = "within")
summary(reg2)

```

```{r}
library(stargazer)
stargazer(reg1, reg2, title="Results", align=TRUE)
```